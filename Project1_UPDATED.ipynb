{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1-UPDATED.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shilpisirohi12/bootcamp/blob/master/Project1_UPDATED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb1PCedn9DCf",
        "colab_type": "text"
      },
      "source": [
        "# **Project #1 - Multiclass classification using MNIST**\n",
        "\n",
        "Classify 28x28 images as one of the 10 digits.\n",
        "\n",
        "![MNIST](https://miro.medium.com/max/700/1*XdCMCaHPt-pqtEibUfAnNw.png)\n",
        "\n",
        "**Source:** https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\n",
        "\n",
        "**0) Runtime type**\n",
        "\n",
        "Before start, change your runtime type on Google Colaboratory to use a GPU as hardware accelerator. To do that, access the menu \"Runtime\" -> \"Change runtime type\", select \"GPU\" in the popup menu and press \"SAVE\".\n",
        "\n",
        "**1) Import libraries**\n",
        "\n",
        "*   **numpy** for data manipulation\n",
        "*   **tensorflow** for neural network conception and training\n",
        "*   **time** for measuring elapsed time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra2yBtA6ILX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from keras.utils.np_utils import to_categorical "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW9L1YEYC-by",
        "colab_type": "text"
      },
      "source": [
        "**2) Load data**\n",
        "\n",
        "Keras hosts several datasets that are commonly used as benchmarks. MNIST is one of them. Normalize pixel values to the range from 0 to 1, and convert images to vectors (row concatenation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JQeIaagMOt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a54fe2be-a802-46d6-cc8d-5bc1bdf05920"
      },
      "source": [
        "#data prep\n",
        "print(\"\\nLoading data...\")\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Reshaping the arrays for the network\n",
        "x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28*28)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_train.dtype, y_train.dtype)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "#converting labels to 1 hot vectors\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading data...\n",
            "(60000, 784) (60000,) uint8 uint8\n",
            "(10000, 784) (10000,)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT80W-IJNCiN",
        "colab_type": "text"
      },
      "source": [
        "**3) Training parameters**\n",
        "\n",
        "Define learning rate, loss function, batch size, number of epochs, and how many times the model must be trained to obtain a reliable performance evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdKOZl6XIDWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "# loss_function = 'mae'\n",
        "loss='categorical_crossentropy'\n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "num_trials = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBqyh-OZNeBq",
        "colab_type": "text"
      },
      "source": [
        "**4) Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z7B_eTYIMgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "outputId": "0db03523-0150-4eb3-b605-df1dfe0b89fb"
      },
      "source": [
        "accs = []\n",
        "train_accs = []\n",
        "times = []\n",
        "\n",
        "for trial in range(num_trials):\n",
        "\t#network architecture: Deep, Big, Simple Neural Nets Excel on Handwritten Digit Recognition, by D. Cireșan, U. Meier, L. Gambardella, and J. Schmidhuber (2010).\n",
        "\tmodel = tf.keras.models.Sequential()\n",
        "\tmodel.add(tf.keras.layers.Dense(1000, activation=\"relu\", input_shape=(784,)))\n",
        "\tmodel.add(tf.keras.layers.Dense(500, activation=\"relu\"))\n",
        "\tmodel.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\tprint(model.summary())\n",
        " \n",
        "  # training configuration\n",
        "\toptimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\tmodel.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "\t#train\n",
        "\tstart = time.time()\n",
        "\tmodel.fit(x=x_train,y=y_train, epochs=num_epochs, batch_size=batch_size)\n",
        "\tend = time.time()\n",
        "\n",
        "\ttotal_train_time = end - start\n",
        "\ttotal_train_time = np.round(total_train_time, 4)\n",
        "\tprint(\"\\nTotal training time in seconds: %2.f\"%total_train_time)\n",
        "\ttimes.append(total_train_time)\n",
        "\n",
        "\t#test eval\n",
        "\tscores = model.evaluate(x_test, y_test)\n",
        "\tacc = scores[1]\n",
        "\tacc = np.round(acc, 4)\n",
        "\tprint(\"\\nTest accuracy:\", acc)\n",
        "\taccs.append(acc)\n",
        "\n",
        "\t#train eval\n",
        "\ttrain_scores = model.evaluate(x_train, y_train)\n",
        "\ttrain_acc = train_scores[1]\n",
        "\ttrain_acc = np.round(train_acc, 4)\n",
        "\tprint(\"\\nTrain accuracy:\", train_acc)\n",
        "\ttrain_accs.append(train_acc)\n",
        "\n",
        "print(\"\\nTrain times: %s\" % str(times))\n",
        "avg_time = np.mean(times)\n",
        "print(\"Average time in seconds:\", avg_time)\n",
        "\n",
        "print(\"\\nTest accuracies: %s\" % str(accs))\n",
        "avg_acc = np.mean(accs)\n",
        "print(\"Average test accuracy:\", avg_acc)\n",
        "\n",
        "print(\"\\nTrain accuracies: %s\" % str(train_accs))\n",
        "avg_train_acc = np.mean(train_accs)\n",
        "print(\"Average train accuracy:\", avg_train_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 1,290,510\n",
            "Trainable params: 1,290,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0194 - accuracy: 0.9065\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0124 - accuracy: 0.9386\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0106 - accuracy: 0.9473\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0104 - accuracy: 0.9477\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0100 - accuracy: 0.9500\n",
            "\n",
            "Total training time in seconds: 35\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9481\n",
            "\n",
            "Test accuracy: 0.9481\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0092 - accuracy: 0.9540\n",
            "\n",
            "Train accuracy: 0.954\n",
            "\n",
            "Train times: [35.4095]\n",
            "Average time in seconds: 35.4095\n",
            "\n",
            "Test accuracies: [0.9481]\n",
            "Average test accuracy: 0.9481\n",
            "\n",
            "Train accuracies: [0.954]\n",
            "Average train accuracy: 0.954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_AMeyoXNmTe",
        "colab_type": "text"
      },
      "source": [
        "**5) Questions:**\n",
        "\n",
        "1.   Run the code and view the model summary. What does the 784 in the (None, 784) tuple represent? Why does the 3rd dense layer has 10 units? How many total parameters are there?\n",
        "\n",
        "2.   Set the learning rate to 0.001 and train for 5 epochs, what’s the test accuracy? How long was training time?\n",
        "\n",
        "3.   What was the training accuracy? Is it higher or lower than the test accuracy?\n",
        "\n",
        "4.   What do you notice about the training loss in each epoch? What does this mean?\n",
        "\n",
        "5.   Set the learning rate to 0.1 and train for 5 epochs, what’s the test accuracy?\n",
        "\n",
        "6.   Set the learning rate to 0.0000001 and train for 5 epochs, what’s the test accuracy?\n",
        "\n",
        "7.   Comment out these lines:\n",
        "\n",
        "\n",
        "> x_train /= 255\n",
        ">\n",
        "> x_test /= 255\n",
        "\n",
        "Set the learning rate to 0.001 and train for 5 epochs, what’s the test accuracy? What conclusion can you draw between the accuracy in this question vs. the accuracy in question 2?\n",
        "\n",
        "8.    Re-insert the normalization lines you commented out in question 6. Comment out the dense layer with 1000 units, and the dense layer with 500 units. Now your model just has 1 dense layer with 10 units. Train and test the model. How many parameters are there? How long did it take to train? What is the test accuracy?\n",
        "\n",
        "9.    Currently, the network has the following architecture: (1000, 500, 10). Each number in that tuple is the number of dense units. Create a network with the following architecture: (2500, 2000, 1500, 1000, 500, 10). Use “relu” activation for every layer except the last dense layer. For that one, use\n",
        "“softmax”. Train and test the model. How many parameters are there? How long did it take to train in seconds? What is the test accuracy?\n",
        "\n",
        "10.   From questions 2 and 8, what conclusion(s) can you draw regarding adding units and layers to a neural network and how they affect (1) accuracy, (2) number of parameters, and (3) training time?\n",
        "\n",
        "11.   Set the loss_function to “mae”. What do you get?\n",
        "\n",
        "12.   Set the batch size to 10000. What’s the test accuracy and how long did it take?\n",
        "\n",
        "13.   Set the batch size to 60000 (size of the training set). What’s the test accuracy and how long did it take?\n",
        "\n",
        "14.   What did you notice about the test accuracy and training time as you increased the batch size to such high numbers? Why might the changes have occurred?"
      ]
    }
  ]
}